# Evaluators

This folder contains the following evaluators:

* [fuzzy_match](./fuzzy_match.py), which uses ROUGE (Recall-Oriented Understudy for Gisting Evaluation) as a means to compare LLM-generated responses against the ground truth.
* [exact_numeric_match](./exact_numeric_match.py), an example evaluator that checks for a match between ground truth and the number of citations.
