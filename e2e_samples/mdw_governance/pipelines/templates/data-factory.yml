# This templates creates a Data Factory instance,
# and optionally links a git repo for storing Data Factory pipelines and data flows
# Set `gitConfigureLater` to true if you don't want the template to link a git repo
#
---
parameters:
  - name: resourceManagerConnection
    type: string
  - name: subscriptionId
    type: string
  - name: resourceGroupName
    type: string
  - name: location
    type: string
  - name: dataFactoryName
    type: string
  - name: logAnalyticsName
    type: string
  - name: diagnosticSettingName
    type: string
  - name: keyVaultName
    type: string
  - name: purviewAccountName
    type: string
  - name: storageAccountName
    type: string
  - name: databricksWorkspaceUrl
    type: string
  - name: databricksClusterId
    type: string
  - name: databricksSecretName
    type: string

steps:
  - task: AzureResourceManagerTemplateDeployment@3
    inputs:
      deploymentScope: 'Resource Group'
      azureResourceManagerConnection: ${{ parameters.resourceManagerConnection }}
      subscriptionId: ${{ parameters.subscriptionId }}
      action: 'Create Or Update Resource Group'
      resourceGroupName: ${{ parameters.resourceGroupName }}
      location: ${{ parameters.location }}
      templateLocation: 'Linked artifact'
      csmFile: './arm-templates/data_factory.json'
      csmParametersFile: './arm-templates/data_factory.parameters.json'
      overrideParameters: >
        -dataFactoryName ${{ parameters.dataFactoryName }}
        -factoryLocation ${{ parameters.location }}
        -logAnalyticsName ${{ parameters.logAnalyticsName }}
        -diagnosticSettingName ${{ parameters.diagnosticSettingName }}
        -keyVaultName ${{ parameters.keyVaultName }}
      deploymentMode: 'Incremental'
    displayName: Create Data Factory

  - task: AzureCLI@2
    inputs:
      azureSubscription: ${{ parameters.resourceManagerConnection }}
      scriptType: 'pscore'
      scriptLocation: 'scriptPath'
      scriptPath: './scripts/environment/New-PurviewADFConnection.ps1'
    env:
      PURVIEW_ACCOUNT_NAME: ${{ parameters.purviewAccountName }}
      KEYVAULT_NAME: ${{ parameters.keyVaultName }}
      DATA_FACTORY_NAME: ${{ parameters.dataFactoryName }}
      RESOURCE_GROUP: ${{ parameters.resourceGroupName }}
    displayName: Link ADF to Purview

  - task: AzureCLI@2
    inputs:
      azureSubscription: ${{ parameters.resourceManagerConnection }}
      scriptType: 'pscore'
      scriptLocation: 'scriptPath'
      scriptPath: './scripts/environment/New-ADFLinkedService.ps1'
    env:
      STORAGE_ACCOUNT_NAME: ${{ parameters.storageAccountName }}
      DATA_FACTORY_NAME: ${{ parameters.dataFactoryName }}
      KEYVAULT_NAME: ${{ parameters.keyVaultName }}
      RESOURCE_GROUP: ${{ parameters.resourceGroupName }}
      DATABRICKS_WORKSPACE_URL: ${{ parameters.databricksWorkspaceUrl }}
      DATABRICKS_CLUSTER_ID: ${{ parameters.databricksClusterId }} 
      DATABRICKS_TOKEN_SECRET_NAME: ${{ parameters.databricksSecretName }}
    displayName: Create ADF links to ADL, AKV and ADB

  - task: AzureCLI@2
    inputs:
      azureSubscription: ${{ parameters.resourceManagerConnection }}
      scriptType: 'pscore'
      scriptLocation: 'scriptPath'
      scriptPath: './scripts/environment/Set-ADL-RBAC.ps1'
    env:
      STORAGE_ACCOUNT_NAME: ${{ parameters.storageAccountName }}
      RESOURCE_NAME: ${{ parameters.dataFactoryName }}
      RESOURCE_TYPE: "Microsoft.DataFactory/factories"
      RESOURCE_GROUP: ${{ parameters.resourceGroupName }}
    displayName: Set container permissions for ADF
