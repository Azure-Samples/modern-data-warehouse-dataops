{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests\n",
    "\n",
    "This notebook demonstrates code focused unit test cases for [nb-city-safety-common.ipynb](../src/notebooks/nb-city-safety-common.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the Notebook - Run only when developing the Notebook\n",
    "\n",
    "- Reference: https://learn.microsoft.com/en-us/fabric/data-engineering/author-notebook-format-code#extend-fabric-notebooks]\n",
    "- **WARNING**: When using formatting using `jupyter_black` it will remove any *cell magic commands* present. You should add them back.\n",
    "\n",
    "```python\n",
    "import jupyter_black\n",
    "jupyter_black.load()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public libraries needed for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import MagicMock, patch, call\n",
    "import pytest\n",
    "import ipytest\n",
    "\n",
    "# this makes the ipytest magic available and raise_on_error causes notebook failure incase of errors\n",
    "ipytest.autoconfig(raise_on_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source the function definitions that need to be tested\n",
    "\n",
    "- In this example we are using `%run` magic to source the function definitions we are going to test. We can also perform `import` if they are part of the environment.\n",
    "- [nb-city-safety-common.ipynb](../src/notebooks/nb-city-safety-common.ipynb) must be in the same Fabric workspace as this notebook.\n",
    "- The external `common_execution_mode` parameter controls which cells to run in the notebook [nb-city-safety-common.ipynb](../src/notebooks/nb-city-safety-common.ipynb).\n",
    "- See [run a notebook](https://learn.microsoft.com/fabric/data-engineering/author-execute-notebook#spark-session-configuration-magic-command) for details about `%run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nb-city-safety-common { \"common_execution_mode\": \"normal\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define local resources and test fixtures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace, metrics\n",
    "from pyspark.sql.functions import (\n",
    "    lit,\n",
    "    to_utc_timestamp,\n",
    "    current_timestamp,\n",
    "    unix_timestamp,\n",
    "    avg,\n",
    "    max,\n",
    "    min,\n",
    "    sum,\n",
    "    count,\n",
    ")\n",
    "\n",
    "# from typing import Optional\n",
    "# from opentelemetry.trace.status import StatusCode\n",
    "tracer = trace.get_tracer(__name__)\n",
    "logger = logging.getLogger(__name__)\n",
    "meter = metrics.get_meter_provider().get_meter(__name__)\n",
    "\n",
    "# from pyspark.sql.functions import col, expr\n",
    "# from pyspark.sql.types import TimestampType\n",
    "# from typing import Optional\n",
    "# from opentelemetry import trace\n",
    "# from opentelemetry.trace.status import StatusCode\n",
    "if spark_major_version >= 3.5:\n",
    "    from pyspark.testing import assertDataFrameEqual, assertSchemaEqual\n",
    "\n",
    "onelake_table_path = \"dummy_path\"\n",
    "table_name = \"test_table\"\n",
    "delta_table_path = f\"{onelake_table_path}/{table_name}\"\n",
    "wasbs_path = \"dumppy_wasbs_path\"\n",
    "cities = [\"city1\", \"city2\"]\n",
    "onelake_name = \"dummy_onelake\"\n",
    "workspace_name = \"dummy_workspace\"\n",
    "lakehouse_name = \"dummy_lakehouse\"\n",
    "job_exec_instance = \"dummy_job_exec_id\"\n",
    "user_name = \"dummy_user_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment shakeout tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env_source_connection():\n",
    "    # TO DO: write unit testcase\n",
    "    assert 1 == 1\n",
    "\n",
    "\n",
    "def test_env_target_connection():\n",
    "    # TO DO: write unit testcase\n",
    "    assert 1 == 1\n",
    "\n",
    "\n",
    "def test_env_keyvault_connection():\n",
    "    # TO DO: write unit testcase\n",
    "    assert 1 == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code-based tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the two lines below to run the tests directly without using ipytest.run()\n",
    "# %%capture captured_output\n",
    "# %%ipytest\n",
    "\n",
    "\n",
    "def test_query_app_insights():\n",
    "    # TO DO: write unit testcase\n",
    "    assert 1 == 1\n",
    "\n",
    "\n",
    "def test_store_unit_test_results():\n",
    "    # TO DO: write unit testcase\n",
    "    assert 1 == 1\n",
    "\n",
    "\n",
    "def test_make_fabric_api_call():\n",
    "    # TO DO: Write unit testcase\n",
    "    assert 1 == 1\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"table_exists, exp_load_mode\", [(False, \"overwrite\"), (True, \"append\")]\n",
    ")\n",
    "@patch(\"__main__.DeltaTable\")\n",
    "def test_identify_table_load_mode(mock_delta, table_exists, exp_load_mode):\n",
    "    mock_span_obj = MagicMock()\n",
    "    mock_delta.isDeltaTable.return_value = table_exists\n",
    "    load_mode = identify_table_load_mode(table_name=table_name, span_obj=mock_span_obj)\n",
    "    mock_span_obj.set_attribute.assert_called_with(\"load_mode\", exp_load_mode)\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"table_exists, expected_logs\",\n",
    "    [\n",
    "        (False, [\"The specified delta table doesn't exist. No need for deletion.\"]),\n",
    "        (\n",
    "            True,\n",
    "            [\n",
    "                f\"Attempting to delete existing delta table with {delta_table_path = }....\",\n",
    "                \"Deleted existing delta table: test_table.\",\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "@patch(\"__main__.notebookutils\")\n",
    "def test_delete_delta_table(mock_mssparkutils, caplog, table_exists, expected_logs):\n",
    "    caplog.clear()\n",
    "    caplog.set_level(logging.INFO)\n",
    "\n",
    "    mock_mssparkutils.fs.exists.return_value = table_exists\n",
    "    result = delete_delta_table(table_name)\n",
    "\n",
    "    if table_exists:\n",
    "        mock_mssparkutils.fs.rm.assert_called_with(dir=delta_table_path, recurse=True)\n",
    "    assert all(log in caplog.text for log in expected_logs)\n",
    "    assert result is None\n",
    "    assert len(caplog.records) == len(expected_logs)\n",
    "\n",
    "\n",
    "@patch(\"__main__.notebookutils\")\n",
    "def test_delete_delta_table_exception(mock_mssparkutils, caplog):\n",
    "    caplog.clear()\n",
    "    caplog.set_level(logging.INFO)\n",
    "\n",
    "    mock_mssparkutils.fs.exists.return_value = True\n",
    "\n",
    "    # Mock an exception being raised during deletion\n",
    "    mock_mssparkutils.fs.rm.side_effect = Exception(\"Deletion failed\")\n",
    "\n",
    "    with pytest.raises(Exception) as exc:\n",
    "        delete_delta_table(table_name)\n",
    "\n",
    "    assert exc.type == Exception\n",
    "    assert str(exc.value) == \"Deletion failed\"\n",
    "\n",
    "    assert (\n",
    "        f\"Attempting to delete existing delta table with {delta_table_path = }....\"\n",
    "        in caplog.text\n",
    "    )\n",
    "    assert f\"Deletion failed with the error:\\n====Deletion failed\\n=====\" in caplog.text\n",
    "    assert len(caplog.records) == 2\n",
    "\n",
    "\n",
    "@patch(\"__main__.transform_data\")\n",
    "@patch(\"__main__.identify_table_load_mode\")\n",
    "@patch(\"__main__.spark\")\n",
    "@patch(\"__main__.tracer\")\n",
    "def test_city_data_etl(\n",
    "    mock_tracer, mock_spark, mock_load_mode, mock_transform_data, caplog\n",
    "):\n",
    "    caplog.clear()\n",
    "    caplog.set_level(logging.INFO)\n",
    "\n",
    "    mock_spark.read.parquet = MagicMock()\n",
    "    mock_spark.read.parquet.return_value.count.return_value = 10\n",
    "    mock_load_mode.return_value = \"overwrite\"\n",
    "\n",
    "    mock_city_span = mock_tracer.start_as_current_span.return_value = MagicMock()\n",
    "    # inputs for current invocation\n",
    "    table_name = \"mydummytable\"\n",
    "    cities = [\"city1\", \"city2\"]\n",
    "    mock_span = MagicMock()\n",
    "    mock_span.add_event = MagicMock()\n",
    "\n",
    "    exp_log_output = []\n",
    "    for city in cities:\n",
    "        exp_log_output += [\n",
    "            f\"ETL started for {city = }.\",\n",
    "            f\"\\t Data Extraction in progress.\",\n",
    "            f\"\\t Read {mock_spark.read.parquet.return_value.count.return_value} records for {city = }.\",\n",
    "            f\"\\t Data loading in inprogress using {mock_load_mode.return_value} mode.\",\n",
    "            f\"ETL completed for {city = }.\",\n",
    "        ]\n",
    "\n",
    "    city_data_etl(table_name, cities, mock_span)\n",
    "\n",
    "    call_count = len(cities)\n",
    "\n",
    "    assert mock_load_mode.call_count == call_count\n",
    "    assert mock_transform_data.call_count == call_count\n",
    "    assert mock_load_mode.call_count == call_count\n",
    "    assert mock_span.add_event.call_count == call_count * 2\n",
    "    assert all(log in caplog.text for log in exp_log_output)\n",
    "\n",
    "    # identifying the calls being made - helpful to write assert statements\n",
    "    # print(mock_tracer.mock_calls)  # print(mock_city_span.mock_calls)\n",
    "    assert (\n",
    "        call.start_as_current_span().__enter__() in mock_tracer.mock_calls\n",
    "    )  # <----trace (with) context call\n",
    "    assert (\n",
    "        mock_tracer.start_as_current_span.call_count == call_count\n",
    "    )  # <----trace (with) context call\n",
    "    assert (\n",
    "        mock_tracer.start_as_current_span.return_value.__enter__.call_count\n",
    "        == call_count\n",
    "    )  # <----trace (with) context-start\n",
    "    assert (\n",
    "        mock_tracer.start_as_current_span.return_value.__enter__.return_value.set_attribute.call_count\n",
    "        == call_count\n",
    "    )\n",
    "    assert (\n",
    "        mock_tracer.start_as_current_span.return_value.__enter__.return_value.add_event.call_count\n",
    "        == call_count * 3\n",
    "    )\n",
    "    assert (\n",
    "        mock_tracer.start_as_current_span.return_value.__enter__.return_value.set_status.call_count\n",
    "        == call_count\n",
    "    )\n",
    "    assert (\n",
    "        mock_tracer.start_as_current_span.return_value.__exit__.call_count == call_count\n",
    "    )  # <--- trace (with) context-end\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\n",
    "    \"cleanup_mode\",\n",
    "    [(False), (True)],\n",
    ")\n",
    "@patch(\"__main__.delete_delta_table\")\n",
    "@patch(\"__main__.city_data_etl\")\n",
    "@patch(\"__main__.trace\")\n",
    "def test_etl_steps(mock_trace, mock_city_etl, mock_del_table, caplog, cleanup_mode):\n",
    "    caplog.clear()\n",
    "    caplog.set_level(logging.INFO)\n",
    "    mock_current_span = mock_trace.get_current_span.return_value = MagicMock()\n",
    "\n",
    "    etl_steps(table_name, cities, cleanup=cleanup_mode)\n",
    "\n",
    "    exp_log_output = [\n",
    "        f\"\\n=====\\nCity safety data is loaded into {table_name =} for {cities =}\\n=====\"\n",
    "    ]\n",
    "\n",
    "    assert mock_current_span.set_attributes.call_count == 1\n",
    "    assert mock_current_span.set_status.call_count == 1\n",
    "    mock_city_etl.assert_called_once_with(table_name, cities, mock_current_span)\n",
    "    if cleanup_mode:\n",
    "        mock_del_table.assert_called_once()\n",
    "        exp_log_output += [\n",
    "            f\"A new delta table '{table_name}' will be created with {delta_table_path = }\"\n",
    "        ]\n",
    "    else:\n",
    "        exp_log_output += [\"No request for cleanup. Proceeding to ETL steps.\"]\n",
    "\n",
    "    assert all(log in caplog.text for log in exp_log_output)\n",
    "\n",
    "\n",
    "@patch(\"__main__.spark\")\n",
    "@patch(\"__main__.meter\")\n",
    "def test_gather_city_level_metrics(mock_meter, mock_spark, caplog):\n",
    "    caplog.clear()\n",
    "    caplog.set_level(logging.INFO)\n",
    "\n",
    "    df = spark.createDataFrame(\n",
    "        data=[(\"Boston\", 1000), (\"Chicago\", 3000)], schema=[\"city\", \"count\"]\n",
    "    )\n",
    "    mock_spark.read.format.return_value.load.return_value = df\n",
    "    df_filter_and_agg = (\n",
    "        mock_spark.createDataFrame.return_value.filter.return_value.groupBy.return_value.agg.return_value.agg.return_value\n",
    "    )\n",
    "    df_filter_and_agg.collect.return_value.__getitem__.return_value.__getitem__.return_value = (\n",
    "        2\n",
    "    )\n",
    "    mock_counter = MagicMock()\n",
    "\n",
    "    gather_city_level_metrics(table_name, mock_counter)\n",
    "\n",
    "    mock_counter.add.assert_called_once_with(\n",
    "        amount=1, attributes={\"record_count_total\": 2}\n",
    "    )\n",
    "    assert \"total:2\" in caplog.text\n",
    "\n",
    "\n",
    "@patch(\"__main__.notebookutils\")\n",
    "@patch(\"__main__.trace.get_current_span\")\n",
    "def test_verify_onelake_connection(mock_span, mock_mssparkutils, caplog):\n",
    "    caplog.clear()\n",
    "    caplog.set_level(logging.INFO)\n",
    "    mock_mssparkutils.fs.ls.return_value = str([\"filepath1\", \"filepath2\"])\n",
    "\n",
    "    # File system exists\n",
    "    mock_mssparkutils.fs.exists.return_value = True\n",
    "    verify_onelake_connection()\n",
    "    mock_span.assert_called_once()\n",
    "    assert len(caplog.records) == 1\n",
    "    assert (\n",
    "        f\"Target table path: {onelake_table_path} is valid and exists.\\nListing source data contents to check connectivity\\n['filepath1', 'filepath2']\"\n",
    "        in caplog.text\n",
    "    )\n",
    "    mock_span.return_value.set_status.assert_called_once()\n",
    "\n",
    "    # Fiel system doesn't exist\n",
    "    mock_mssparkutils.fs.exists.return_value = False\n",
    "    verify_onelake_connection()\n",
    "    print(mock_span.mock_calls)\n",
    "    print(mock_mssparkutils.mock_calls)\n",
    "    assert (\n",
    "        \"Error message: Encountered error while checking for Lakehouse table path specified.\"\n",
    "        in caplog.text\n",
    "    )\n",
    "    mock_span.return_value.record_exception.assert_called_once()\n",
    "    mock_span.return_value.set_status.assert_called()\n",
    "    mock_mssparkutils.notebook.exit.assert_called_once_with(\n",
    "        f\"Specfied lakehouse table path {onelake_table_path} doesn't exist. Ensure onelake={onelake_name}, workspace={workspace_name} and lakehouse={lakehouse_name} exist.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-based tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    \"city, test_data\",\n",
    "    [\n",
    "        (\n",
    "            \"Boston\",\n",
    "            [(\"event1\", \"2022-01-01T00:00:00\"), (\"event2\", \"2022-01-01T23:00:00\")],\n",
    "        ),\n",
    "        (\n",
    "            \"Seattle\",\n",
    "            [(\"event1\", \"2022-01-01T00:00:00\"), (\"event2\", \"2022-01-01T23:00:00\")],\n",
    "        ),\n",
    "        (\n",
    "            \"Chicago\",\n",
    "            [(\"event1\", \"2022-01-01T00:00:00\"), (\"event2\", \"2022-01-01T23:00:00\")],\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "@patch(\"__main__.to_utc_timestamp\")\n",
    "def test_transform_data(mock_utcts, city, test_data):\n",
    "\n",
    "    # This is dataframe col of timestamp type\n",
    "    date_output_value = lit(\"2022-12-31T23:00:00\").cast(TimestampType())\n",
    "    mock_utcts.return_value = date_output_value\n",
    "    test_df = spark.createDataFrame(test_data, [\"event_name\", \"dateTime\"])\n",
    "    test_df = test_df.withColumn(\"dateTime\", col(\"dateTime\").cast(TimestampType()))\n",
    "\n",
    "    act_df = test_df.withColumns(\n",
    "        {\n",
    "            \"dateTimeUTC\": date_output_value,\n",
    "            \"City\": lit(city),\n",
    "            \"jobExecId\": lit(job_exec_instance),\n",
    "            \"lastUpdateUTC\": date_output_value,\n",
    "            \"lastUpdateUser\": lit(user_name),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    exp_df = transform_data(city, test_df)\n",
    "\n",
    "    # works in spark 3.5 +\n",
    "    # - If using earlier realeases compare columns, and then data collect statements to compare records\n",
    "    if spark_major_version >= 3.5:\n",
    "        assertDataFrameEqual(act_df, exp_df)\n",
    "    else:\n",
    "        # Compare the DataFrames\n",
    "        assert exp_df.exceptAll(act_df).count() == 0\n",
    "        assert exp_df.schema == act_df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the testcases and capture the output\n",
    "\n",
    "- As `ipytest.autoconfig(raise_on_error=True)` was used in the begining of this notebook, any errors from the testcases will not result in notebook failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "ipytest.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the test rsults\n",
    "\n",
    "- These can be stored somewhere or sent for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_unit_test_results(captured_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
