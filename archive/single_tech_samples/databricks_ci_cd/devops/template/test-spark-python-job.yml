parameters:
- name: environmentName
  type: string
- name: databricksDomain
  type: string
- name: databricksClusterId
  type: string
- name: databricksToken
  type: string
- name: databricksJobName
  type: string
- name: databricksArtifactsPath
  type: string

jobs:
- deployment: test_spark_python
  dependsOn: test_libs
  environment: ${{ parameters.environmentName }}
  displayName: 'Test spark python job'
  pool:
    vmImage: 'ubuntu-latest'
  variables:
    pythonVersion: 3.8
    deploymenFile: './temp_deployment_spark_python.json'
  strategy:
    runOnce:
      deploy:
        steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(pythonVersion)'
            addToPath: true
            architecture: 'x64'
          displayName: 'Use Python Version: $(pythonVersion)'

        - checkout: self
          persistCredentials: true
          clean: true
          displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'


        - script: |
            python -m pip install --upgrade pip
            pip install -r requirements.txt
            pip install -e .
          displayName: 'Install dependencies'


        - template: create-deployment-json.yml
          parameters:
            configFile: './conf/deployment_spark_python_new_cluster.json'
            databricksClusterId: '${{ parameters.databricksClusterId}}' # not used, new cluster
            databricksJobName: '${{ parameters.databricksJobName}}'
            databricksArtifactsPath: '${{ parameters.databricksArtifactsPath}}'
            databricksDeploymentFilePath: $(deploymenFile)
          

        - script: |
            echo "dbx deploy job $DATABRICKS_JOB_NAME ..."
            dbx deploy --deployment-file=$(deploymenFile) --jobs=$DATABRICKS_JOB_NAME --assets-only
          displayName: 'Deploy Spark Python Job'
          env:
            DATABRICKS_HOST: ${{ parameters.databricksDomain }}
            DATABRICKS_TOKEN: ${{ parameters.databricksToken }}
            DATABRICKS_JOB_NAME: ${{ parameters.databricksJobName}}

        - script: |
            echo "dbx launch job $DATABRICKS_JOB_NAME ..."
            dbx launch $DATABRICKS_JOB_NAME --as-run-submit --trace
          displayName: 'Launch integration on test'
          env:
            DATABRICKS_HOST: ${{ parameters.databricksDomain }}
            DATABRICKS_TOKEN: ${{ parameters.databricksToken }}
            DATABRICKS_JOB_NAME: ${{ parameters.databricksJobName}}
