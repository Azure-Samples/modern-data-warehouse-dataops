# Databricks notebook source
dbutils.fs.refreshMounts()
dbutils.fs.mounts()

# COMMAND ----------

if "/mnt/sample-container" not in list(map(lambda mnt: mnt.mountPoint, dbutils.fs.mounts())):
  dbutils.fs.mount(
    source = "wasbs://sample-container@${DEPLOYMENT_PREFIX}asa01.blob.core.windows.net",
    mount_point = "/mnt/sample-container",
    extra_configs = {"fs.azure.account.key.${DEPLOYMENT_PREFIX}asa01.blob.core.windows.net":dbutils.secrets.get(scope = "storage_scope", key = "StorageAccountKey1")})
dbutils.fs.refreshMounts()
dbutils.fs.mounts()

# COMMAND ----------

df = spark.read.json("/mnt/sample-container/sample-data.us-population.json")
display(df)