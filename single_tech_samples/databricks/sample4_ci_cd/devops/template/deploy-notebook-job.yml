parameters:
- name: environmentName
  type: string
- name: databricksDomain
  type: string
- name: databricksToken
  type: string
- name: databricksNotebookPath
  type: string

jobs:
- deployment: deploy_notebooks
  dependsOn: deploy_libs
  environment: ${{ parameters.environmentName }}
  displayName: 'Deploy notebooks to Databricks'
  pool:
    vmImage: 'ubuntu-latest'
  variables:
    pythonVersion: 3.8
  strategy:
    runOnce:
      deploy:
        steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '$(pythonVersion)'
            addToPath: true
            architecture: 'x64'
          displayName: 'Use Python Version: $(pythonVersion)'

        - checkout: self
          persistCredentials: true
          clean: true
          displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'

        - task: CopyFiles@2
          inputs:
            SourceFolder: './notebook_jobs'
            contents: '**'
            targetFolder: $(Build.ArtifactStagingDirectory)
          displayName: 'Copy notebook folder'

        - script: |
            python -m pip install --upgrade pip
            pip install databricks-cli
          displayName: 'Setup Databricks CLI'
          
        - script: |
            echo "Uploading notebooks at $(Build.ArtifactStagingDirectory) to workspace (${DATABRICKS_NOTEBOOK_PATH}) ..."
            databricks workspace import_dir --overwrite "$(Build.ArtifactStagingDirectory)" "${DATABRICKS_NOTEBOOK_PATH}"
          env:
            DATABRICKS_HOST: ${{ parameters.databricksDomain }}
            DATABRICKS_TOKEN: ${{ parameters.databricksToken }}
            DATABRICKS_NOTEBOOK_PATH: ${{ parameters.databricksNotebookPath }}
          displayName: 'Deploy notebooks'
